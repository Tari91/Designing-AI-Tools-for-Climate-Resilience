import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split

import torch
import torch.nn as nn
import torch.optim as optim

def generate_synthetic_climate_data(num_samples=10000):
    np.random.seed(42)

    # Simulate features
    temperature = np.random.normal(loc=30, scale=5, size=num_samples)
    precipitation = np.random.exponential(scale=50, size=num_samples)
    humidity = np.random.uniform(20, 90, num_samples)
    wind_speed = np.random.normal(loc=10, scale=3, size=num_samples)
    vegetation_index = np.random.uniform(0.2, 0.9, num_samples)

    # Target label: 1 = high climate risk, 0 = low risk
    risk_score = (
        (temperature > 35).astype(int) +
        (precipitation < 20).astype(int) +
        (humidity < 30).astype(int) +
        (wind_speed > 15).astype(int) +
        (vegetation_index < 0.4).astype(int)
    )

    # Define risk threshold
    climate_risk = (risk_score >= 3).astype(int)

    # Combine into DataFrame
    df = pd.DataFrame({
        'temperature': temperature,
        'precipitation': precipitation,
        'humidity': humidity,
        'wind_speed': wind_speed,
        'vegetation_index': vegetation_index,
        'climate_risk': climate_risk
    })

    return df
def train_random_forest(df):
    X = df.drop(columns=['climate_risk'])
    y = df['climate_risk']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    y_pred = model.predict(X_test)

    print("Classification Report:\n", classification_report(y_test, y_pred))
    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="YlGnBu")
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.show()

    return model
class ClimateRiskNN(nn.Module):
    def __init__(self):
        super(ClimateRiskNN, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(5, 16),
            nn.ReLU(),
            nn.Linear(16, 8),
            nn.ReLU(),
            nn.Linear(8, 2)
        )

    def forward(self, x):
        return self.net(x)

def train_nn(df):
    X = df.drop(columns=['climate_risk']).values.astype(np.float32)
    y = df['climate_risk'].values.astype(np.int64)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    model = ClimateRiskNN()
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    X_train_tensor = torch.tensor(X_train)
    y_train_tensor = torch.tensor(y_train)
    X_test_tensor = torch.tensor(X_test)
    y_test_tensor = torch.tensor(y_test)

    for epoch in range(50):
        model.train()
        optimizer.zero_grad()
        output = model(X_train_tensor)
        loss = criterion(output, y_train_tensor)
        loss.backward()
        optimizer.step()

        if epoch % 10 == 0:
            print(f"Epoch {epoch}, Loss: {loss.item():.4f}")

    # Evaluation
    model.eval()
    with torch.no_grad():
        preds = model(X_test_tensor).argmax(dim=1)
        acc = (preds == y_test_tensor).float().mean()
        print(f"Test Accuracy: {acc.item():.2%}")

if __name__ == "__main__":
    df = generate_synthetic_climate_data()
    print(df.head())

    print("\n--- Training Random Forest Model ---")
    rf_model = train_random_forest(df)

    print("\n--- Training Neural Network Model ---")
    train_nn(df)
